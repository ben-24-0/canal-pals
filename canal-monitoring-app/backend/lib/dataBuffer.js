/**
 * In-memory data buffer for ESP32 readings.
 *
 * - Every incoming reading is pushed to a per-canal buffer array
 *   AND stored as the "latest" reading for that canal.
 * - A setInterval flushes all buffered readings to MongoDB every
 *   FLUSH_INTERVAL_MS (default 10 min, configurable via .env).
 * - The frontend reads from `getLatest()` / `getAll()` for real-time
 *   data â€” no MongoDB round-trip needed.
 */

const CanalReading = require("../models/CanalReading");

// â”€â”€ Configuration â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
const FLUSH_INTERVAL_MS =
  (parseInt(process.env.ESP32_BUFFER_FLUSH_INTERVAL, 10) || 600) * 1000; // default 600s = 10 min

// â”€â”€ State â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
// canalId â†’ { latest: <reading obj>, buffer: [<reading obj>, ...] }
const store = new Map();

let flushTimer = null;

// â”€â”€ Public API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/** Push a new reading into the buffer and update "latest". */
function push(canalId, readingObj) {
  if (!store.has(canalId)) {
    store.set(canalId, { latest: null, buffer: [] });
  }
  const entry = store.get(canalId);
  entry.latest = readingObj;
  entry.buffer.push(readingObj);
}

/** Get the most recent reading for one canal (from memory). */
function getLatest(canalId) {
  const entry = store.get(canalId);
  return entry ? entry.latest : null;
}

/** Get the most recent reading for ALL canals (from memory). */
function getAll() {
  const result = {};
  for (const [canalId, entry] of store) {
    result[canalId] = entry.latest;
  }
  return result;
}

/** Get the full buffer for one canal (readings not yet flushed). */
function getBuffer(canalId) {
  const entry = store.get(canalId);
  return entry ? [...entry.buffer] : [];
}

/** Get buffer sizes for monitoring. */
function getBufferStats() {
  const stats = {};
  for (const [canalId, entry] of store) {
    stats[canalId] = {
      buffered: entry.buffer.length,
      latestTimestamp: entry.latest?.timestamp || entry.latest?.receivedAt,
    };
  }
  return stats;
}

// â”€â”€ Flush logic â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/** Bulk-insert all buffered readings to MongoDB, then clear buffers. */
async function flush() {
  // Collect all readings from every canal buffer
  const allReadings = [];
  for (const [, entry] of store) {
    allReadings.push(...entry.buffer);
  }

  if (allReadings.length === 0) {
    console.log("â© [FLUSH] Nothing to flush â€” buffers empty.");
    return { inserted: 0 };
  }

  try {
    // insertMany is much more efficient than individual saves
    const result = await CanalReading.insertMany(allReadings, {
      ordered: false, // continue on duplicate-key errors
    });

    const insertedCount = result.length;

    // Clear all buffers (keep latest intact)
    for (const [, entry] of store) {
      entry.buffer = [];
    }

    console.log(
      `âœ… [FLUSH] Bulk-inserted ${insertedCount} readings to MongoDB.`,
    );
    return { inserted: insertedCount };
  } catch (error) {
    // With ordered:false, some may still have been inserted
    const insertedCount = error.insertedDocs?.length || 0;

    // Clear buffers even on partial success to avoid re-inserting
    for (const [, entry] of store) {
      entry.buffer = [];
    }

    console.error(
      `âš ï¸  [FLUSH] Partial flush: ${insertedCount} inserted, errors:`,
      error.message,
    );
    return { inserted: insertedCount, error: error.message };
  }
}

/** Start the automatic flush timer. Call once at server startup. */
function startFlushTimer() {
  if (flushTimer) return; // already running

  flushTimer = setInterval(async () => {
    console.log("ðŸ”„ [FLUSH] Auto-flush triggeredâ€¦");
    await flush();
  }, FLUSH_INTERVAL_MS);

  // Don't let the timer keep the process alive on shutdown
  flushTimer.unref();

  console.log(
    `ðŸ“¦ [BUFFER] Flush timer started â€” every ${FLUSH_INTERVAL_MS / 1000}s`,
  );
}

/** Stop the timer and do a final flush (call on graceful shutdown). */
async function stopAndFlush() {
  if (flushTimer) {
    clearInterval(flushTimer);
    flushTimer = null;
  }
  console.log("ðŸ›‘ [BUFFER] Final flush before shutdownâ€¦");
  return flush();
}

// â”€â”€ Export â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
module.exports = {
  push,
  getLatest,
  getAll,
  getBuffer,
  getBufferStats,
  flush,
  startFlushTimer,
  stopAndFlush,
  FLUSH_INTERVAL_MS,
};
